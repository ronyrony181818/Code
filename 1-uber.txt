# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy import stats

# Load the dataset
data = pd.read_csv("uber.csv")
# Display dataset information and check for missing values
print(data.info())
print(data.isnull().sum())

# Drop rows with missing values
data = data.dropna()

# Convert pickup datetime to datetime format
data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])

# Extract useful features from datetime
data['pickup_hour'] = data['pickup_datetime'].dt.hour
data['pickup_day'] = data['pickup_datetime'].dt.day
data['pickup_month'] = data['pickup_datetime'].dt.month
data['pickup_day_of_week'] = data['pickup_datetime'].dt.dayofweek

# Drop unnecessary columns
data = data.drop(columns=['pickup_datetime', 'key'])
# Visualize fare_amount distribution
sns.boxplot(x=data['fare_amount'])
plt.show()

# Remove outliers from fare_amount (assuming values below 0 or above a certain threshold are outliers)
fare_upper_limit = data['fare_amount'].quantile(0.99)  # Set an upper limit (e.g., 99th percentile)
data = data[(data['fare_amount'] > 0) & (data['fare_amount'] <= fare_upper_limit)]

# Visualize again to confirm removal of extreme outliers
sns.boxplot(x=data['fare_amount'])
plt.show()

# Compute correlation matrix
correlation_matrix = data.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.show()

# Separate features and target variable
X = data.drop(columns=['fare_amount'])
y = data['fare_amount']

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Make predictions and calculate metrics
linear_pred = linear_model.predict(X_test)
linear_rmse = np.sqrt(mean_squared_error(y_test, linear_pred))
linear_r2 = r2_score(y_test, linear_pred)

print("Linear Regression RMSE:", linear_rmse)
print("Linear Regression R²:", linear_r2)

# Initialize and train the Random Forest Regressor model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions and calculate metrics
rf_pred = rf_model.predict(X_test)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))
rf_r2 = r2_score(y_test, rf_pred)

print("Random Forest Regression RMSE:", rf_rmse)
print("Random Forest Regression R²:", rf_r2)

print("Model Comparison:")
print(f"Linear Regression - RMSE: {linear_rmse:.2f}, R²: {linear_r2:.2f}")
print(f"Random Forest - RMSE: {rf_rmse:.2f}, R²: {rf_r2:.2f}")

